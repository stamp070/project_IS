import streamlit as st

st.set_page_config(page_title="ML document", layout="wide")

# ‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤
st.title("üìå Machine Learning Code Explanation")
st.write("\nüí° ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏û‡∏ä‡∏£‡∏î‡πâ‡∏ß‡∏¢ Machine Learning")

# ‡πÅ‡∏ö‡πà‡∏á Section
st.header("1Ô∏è‚É£ Data Exploration & Cleaning üßº")

st.subheader("üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô")
st.write("‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Diamonds_Prices.csv")
st.code("""
df = pd.read_csv("Diamonds_Prices.csv")
df.head()
df.tail()
""", language="python")

# ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
st.image("./image/ML/1.png", caption="üîπ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Head & Tail)")

st.subheader("üõ† ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ (Missing Values)")
st.code("""
df.isnull().sum()
""", language="python")
st.image("./image/ML/2.png", caption="üîπ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ Missing Values")
st.write("---")

st.header("2Ô∏è‚É£ Data Cleaning & Preprocessing üßΩ")
st.subheader("üóë ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô")
st.write("‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Unnamed: 0 ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•")
st.code("df = df.drop(columns='Unnamed: 0', errors='ignore')", language="python")
st.image("./image/ML/3.png", caption="üîπ ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Unnamed: 0")

st.subheader("üìä ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà")
st.write("‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (Categorical Features)")
st.code("""
text_features = ["cut", "clarity", "color"]
fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for i, feature in enumerate(text_features):
    df[feature].value_counts().plot(kind='bar', ax=axes[i])
    axes[i].set_title(f"Distribution of {feature}")
    axes[i].set_xlabel(feature)
    axes[i].set_ylabel("Count")
plt.tight_layout()
plt.show()
""", language="python")
st.image("./image/ML/4.png", caption="üîπ ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà")

st.subheader("üìä ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç")
st.write("‡πÉ‡∏ä‡πâ describe() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç")
st.code("df.describe()", language="python")
st.image("./image/ML/5.png", caption="üîπ ‡∏Ñ‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç")

st.subheader("üìå Correlation Analysis")
st.write("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Heatmap")
st.code("""
sns.heatmap(df.corr(numeric_only=True), annot=True")
""", language="python")
st.image("./image/ML/6.png", caption="üîπ Correlation Heatmap")

st.subheader("üìå ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç")
st.write("‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏û‡∏ö‡∏ß‡πà‡∏≤ Depth ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏ï‡πà‡∏≥‡∏Å‡∏±‡∏ö Price ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡πÑ‡∏î‡πâ")
st.code("df = df.drop(columns=['depth'])", language="python")
st.image("./image/ML/7.png", caption="üîπ ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Depth ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å Dataframe")
st.write("---")


st.header("3Ô∏è‚É£ Feature Engineering & Preprocessing üõ†")
st.subheader("üìå ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Outliers ‡∏î‡πâ‡∏ß‡∏¢ IQR Method")
st.code("""
def no_outliers(column):
    if column.dtype in ['float64', 'int64']:
        q1, q3 = column.quantile([0.25, 0.75])
        lower_limit = q1 - 1.5 * (q3 - q1)
        upper_limit = q3 + 1.5 * (q3 - q1)
        column = column.clip(lower=lower_limit, upper=upper_limit)
    return column
df = no_outliers(df)
""", language="python")
st.image("./image/ML/8.png", caption="üîπ ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Depth ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å Dataframe")

st.subheader("üìå Scaling & Encoding")
st.code("""
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import make_column_transformer

num_features = ["carat", "table", "x", "y", "z"]
cat_features = ["cut", "color", "clarity"]

preprocessor = make_column_transformer(
    (StandardScaler(), num_features),
    (OneHotEncoder(handle_unknown="ignore"), cat_features),
    remainder="drop"
)
""", language="python")
st.image("./image/ML/9.png", caption="üîπ Scaling & Encoding")
st.write("---")

st.header("4Ô∏è‚É£ Model Training & Evaluation üéØ")

st.subheader("üìå ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö")
st.write("""
‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÄ‡∏£‡∏≤‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô **‡∏ä‡∏∏‡∏î‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô (Training set)** ‡πÅ‡∏•‡∏∞ **‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö (Testing set)** 
‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
""")
st.code("""
from sklearn.model_selection import train_test_split
X = df.[feature]
y = df[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
""", language="python")

st.subheader("üìå ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•")
st.write("""
‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• **Random Forest Regressor** ‡πÅ‡∏•‡∏∞ **Support Vector Regressor (SVR)** 
‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡∏°‡∏≤‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏û‡∏ä‡∏£
- **Random Forest Regressor**: ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à (Decision Trees) 
‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Overfitting
- **Support Vector Regressor (SVR)**: ‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á **Support Vector Machine (SVM)** 
‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏™‡πâ‡∏ô‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
""")
st.code("""
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR

# ‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Random Forest
rf_model = RandomForestRegressor(n_estimators=300, max_depth=15, min_samples_split=5, min_samples_leaf=2, random_state=42)
rf_model.fit(X_train, y_train)

# ‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• SVR
svr_model = SVR(kernel='rbf', C=100, gamma=0.01, epsilon=0.1, max_iter=10000)
svr_model.fit(X_train, y_train)
""", language="python")

# ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
st.image("./image/ML/10.png", caption="üîπ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Random Forest")
st.image("./image/ML/11.png", caption="üîπ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Random SVR")


st.subheader("üìå ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•")
st.write("""
‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡∏î‡∏µ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÉ‡∏î ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
- **R¬≤ (Coefficient of Determination)**: ‡∏ß‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏î‡πâ‡∏î‡∏µ‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô (‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ 1 ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÅ‡∏™‡∏î‡∏á‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á)
- **MAE (Mean Absolute Error)**: ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÑ‡∏î‡πâ
- **RMSE (Root Mean Squared Error)**: ‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
""")
st.code("""
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    return {"R¬≤": r2, "MAE": mae, "RMSE": rmse}

rf_metrics = evaluate_model(rf_model, X_test, y_test)
svr_metrics = evaluate_model(svr_model, X_test, y_test)
rf_metrics, svr_metrics
""", language="python")

# ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
st.image("./image/ML/12.png", caption="üîπ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Random Forest ‡πÅ‡∏•‡∏∞ SVR")

st.write("üìä **‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•**")
st.write("""
- **Random Forest**
  - R¬≤: **0.97**
  - MAE: **219.95**
  - RMSE: **377.12**
- **SVR**
  - R¬≤: **0.91**
  - MAE: **466.32**
  - RMSE: **765.65**
""")
st.write("""
‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ‡πÇ‡∏°‡πÄ‡∏î‡∏• **Random Forest** ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ **SVR** ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ **R¬≤ ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤** 
‡πÅ‡∏•‡∏∞ **MAE & RMSE ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤** ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤ Random Forest ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏û‡∏ä‡∏£‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ô‡∏µ‡πâ
""")
st.write("---")

# -------------------------------------------
# 5Ô∏è‚É£ Model Testing with Random Data üî¨
# -------------------------------------------
st.header("5Ô∏è‚É£ Model Testing with Random Data üî¨")

st.subheader("üìå Generating Random Diamond Data")
st.write("‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏à‡∏∂‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô‡∏™‡∏∏‡πà‡∏°‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏û‡∏ä‡∏£‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏£‡∏≤‡∏Ñ‡∏≤")

st.code("""
import numpy as np

cut_options = ["Fair", "Good", "Very Good", "Premium", "Ideal"]
color_options = ["D", "E", "F", "G", "H", "I", "J"]
clarity_options = ["I1", "SI2", "SI1", "VS2", "VS1", "VVS2", "VVS1", "IF"]

def generate_random_diamond():
    return {
        "carat": np.random.uniform(0.5, 1.3),
        "cut": np.random.choice(cut_options, p=[0.10, 0.15, 0.25, 0.30, 0.20]),
        "color": np.random.choice(color_options, p=[0.15, 0.15, 0.15, 0.15, 0.13, 0.12, 0.05]),
        "clarity": np.random.choice(clarity_options, p=[0.08, 0.10, 0.15, 0.15, 0.18, 0.15, 0.12, 0.07]),
        "table": np.random.uniform(56, 59),
        "x": np.random.uniform(4.5, 6.5),
        "y": np.random.uniform(4.7, 6.5),
        "z": np.random.uniform(2.8, 4)
    }

# Generate 5 random samples
random_diamonds = [generate_random_diamond() for _ in range(5)]
random_diamonds = pd.DataFrame(random_diamonds)
random_test_rf = rf_pipeline.predict(random_diamonds)
random_test_svr = svr_pipeline.predict(random_diamonds)
        
# Print        
print(random_test_rf)
print(random_test_svr)
""", language="python")

st.image("./image/ML/13.png", caption="üîπ Sample of Randomly Generated Diamond Data")

st.subheader("üìå Deploy on Streamlit")
st.write("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏Ç‡πâ‡∏≤ Streamlit ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏û‡∏ä‡∏£‡πÅ‡∏ö‡∏ö Interactive")
st.code("""
import joblib
joblib.dump(rf_model, "rf_model.pkl")
joblib.dump(svr_model, "svr_model.pkl")
""", language="python")
st.write("---")
